#!/usr/bin/env python3
"""
Comprehensive tests for conversation history lifecycle: save â†’ retrieve â†’ cleanup.
Tests the complete flow of conversation records through the system.
"""

import asyncio
from datetime import datetime, timedelta

import pytest

from mcp_as_a_judge.db.providers.sqlite_provider import SQLiteProvider


class TestConversationHistoryLifecycle:
    """Test the complete lifecycle of conversation history records."""

    @pytest.mark.asyncio
    async def test_save_retrieve_fifo_cleanup_lifecycle(self):
        """Test complete lifecycle: save â†’ retrieve â†’ FIFO cleanup."""
        # Create provider with small limit for testing
        db = SQLiteProvider(max_session_records=3)
        session_id = "lifecycle_test_session"

        print("\nðŸ”„ TESTING COMPLETE CONVERSATION HISTORY LIFECYCLE")
        print("=" * 60)

        # PHASE 1: Save initial records (within limit)
        print("ðŸ“ PHASE 1: Saving initial records...")
        record_ids = []
        for i in range(3):
            record_id = await db.save_conversation(
                session_id=session_id,
                source=f"tool_{i}",
                input_data=f"Input for tool {i}",
                output=f"Output from tool {i}",
            )
            record_ids.append(record_id)
            print(f"   Saved record {i}: {record_id}")

        # Verify all records are saved
        records = await db.get_session_conversations(session_id)
        assert len(records) == 3, f"Expected 3 records, got {len(records)}"
        print(f"âœ… Phase 1: {len(records)} records saved successfully")

        # PHASE 2: Retrieve and verify order
        print("\nðŸ“– PHASE 2: Retrieving and verifying order...")
        records = await db.get_session_conversations(session_id)

        # Records should be in reverse chronological order (newest first)
        sources = [r.source for r in records]
        expected_sources = ["tool_2", "tool_1", "tool_0"]  # Newest first
        # Note: Due to timestamp precision, order might vary, so check if we have all records
        assert set(sources) == set(expected_sources), (
            f"Expected {set(expected_sources)}, got {set(sources)}"
        )

        # Verify timestamps are in descending order
        timestamps = [r.timestamp for r in records]
        for i in range(len(timestamps) - 1):
            assert timestamps[i] >= timestamps[i + 1], (
                "Records should be ordered newest first"
            )

        print(f"âœ… Phase 2: Records retrieved in correct order: {sources}")

        # PHASE 3: Trigger FIFO cleanup by adding more records
        print("\nðŸ§¹ PHASE 3: Triggering FIFO cleanup...")

        # Add 2 more records (should trigger cleanup of oldest)
        for i in range(3, 5):
            record_id = await db.save_conversation(
                session_id=session_id,
                source=f"tool_{i}",
                input_data=f"Input for tool {i}",
                output=f"Output from tool {i}",
            )
            print(f"   Added record {i}: {record_id}")

        # Verify FIFO cleanup worked
        records = await db.get_session_conversations(session_id)
        assert len(records) == 3, (
            f"Expected 3 records after cleanup, got {len(records)}"
        )

        # Should have the 3 most recent records
        sources = [r.source for r in records]
        expected_sources = ["tool_4", "tool_3", "tool_2"]  # Most recent 3
        assert sources == expected_sources, (
            f"Expected {expected_sources}, got {sources}"
        )

        print(f"âœ… Phase 3: FIFO cleanup worked correctly: {sources}")

        # PHASE 4: Verify specific record retrieval
        print("\nðŸ” PHASE 4: Verifying record content...")

        # Check that oldest records were actually removed
        all_sources = [r.source for r in records]
        assert "tool_0" not in all_sources, "tool_0 should have been cleaned up"
        assert "tool_1" not in all_sources, "tool_1 should have been cleaned up"
        assert "tool_4" in all_sources, "tool_4 should be present (newest)"

        # Verify record content integrity
        newest_record = records[0]  # Should be tool_4
        assert newest_record.source == "tool_4"
        assert newest_record.input == "Input for tool 4"
        assert newest_record.output == "Output from tool 4"
        assert newest_record.session_id == session_id

        print("âœ… Phase 4: Record content verified successfully")

        print("\nðŸŽ‰ COMPLETE LIFECYCLE TEST PASSED!")
        print("âœ… Save: Records saved correctly")
        print("âœ… Retrieve: Records retrieved in correct order")
        print("âœ… FIFO Cleanup: Oldest records removed when limit exceeded")
        print("âœ… Content Integrity: Record data preserved correctly")

    @pytest.mark.asyncio
    async def test_multiple_sessions_isolation(self):
        """Test that FIFO cleanup works independently per session."""
        db = SQLiteProvider(max_session_records=2)

        print("\nðŸ”„ TESTING MULTI-SESSION ISOLATION")
        print("=" * 60)

        # Add records to session A
        for i in range(3):
            await db.save_conversation(
                session_id="session_A",
                source=f"tool_A_{i}",
                input_data=f"Input A {i}",
                output=f"Output A {i}",
            )

        # Add records to session B
        for i in range(4):
            await db.save_conversation(
                session_id="session_B",
                source=f"tool_B_{i}",
                input_data=f"Input B {i}",
                output=f"Output B {i}",
            )

        # Verify session A has only 2 records (FIFO cleanup)
        records_a = await db.get_session_conversations("session_A")
        assert len(records_a) == 2
        sources_a = [r.source for r in records_a]
        # Check that we have the most recent 2 records (order may vary due to timestamp precision)
        assert set(sources_a) == {"tool_A_2", "tool_A_1"}, f"Expected most recent 2, got {sources_a}"

        # Verify session B has only 2 records (FIFO cleanup)
        records_b = await db.get_session_conversations("session_B")
        assert len(records_b) == 2
        sources_b = [r.source for r in records_b]
        assert sources_b == ["tool_B_3", "tool_B_2"]  # Most recent 2

        print("âœ… Multi-session isolation: Each session cleaned up independently")
        print(f"   Session A: {sources_a}")
        print(f"   Session B: {sources_b}")

    @pytest.mark.asyncio
    async def test_time_based_cleanup_integration(self):
        """Test integration of FIFO cleanup with time-based cleanup."""
        db = SQLiteProvider(max_session_records=5)

        print("\nðŸ”„ TESTING TIME-BASED CLEANUP INTEGRATION")
        print("=" * 60)

        # Add some records
        for i in range(3):
            await db.save_conversation(
                session_id="time_test_session",
                source=f"tool_{i}",
                input_data=f"Input {i}",
                output=f"Output {i}",
            )

        # Verify records exist
        records_before = await db.get_session_conversations("time_test_session")
        assert len(records_before) == 3
        print(f"âœ… Before cleanup: {len(records_before)} records")

        # Force time-based cleanup by mocking old cleanup time
        old_time = datetime.utcnow() - timedelta(days=2)
        db._last_cleanup_time = old_time

        # Trigger cleanup by adding another record
        await db.save_conversation(
            session_id="time_test_session",
            source="tool_trigger",
            input_data="Trigger cleanup",
            output="Cleanup triggered",
        )

        # Records should still exist (within retention period)
        records_after = await db.get_session_conversations("time_test_session")
        assert len(records_after) == 4
        print(
            f"âœ… After time-based cleanup: {len(records_after)} records (within retention)"
        )

        print("âœ… Time-based cleanup integration working correctly")

    @pytest.mark.asyncio
    async def test_edge_cases_and_error_handling(self):
        """Test edge cases in the conversation history lifecycle."""
        db = SQLiteProvider(max_session_records=2)

        print("\nðŸ”„ TESTING EDGE CASES")
        print("=" * 60)

        # Test empty session
        empty_records = await db.get_session_conversations("nonexistent_session")
        assert len(empty_records) == 0
        print("âœ… Empty session handling: No records returned")

        # Test single record
        await db.save_conversation(
            session_id="single_record_session",
            source="single_tool",
            input_data="Single input",
            output="Single output",
        )

        single_records = await db.get_session_conversations("single_record_session")
        assert len(single_records) == 1
        assert single_records[0].source == "single_tool"
        print("âœ… Single record handling: Correct retrieval")

        # Test exact limit (no cleanup needed)
        for i in range(2):
            await db.save_conversation(
                session_id="exact_limit_session",
                source=f"exact_tool_{i}",
                input_data=f"Exact input {i}",
                output=f"Exact output {i}",
            )

        exact_records = await db.get_session_conversations("exact_limit_session")
        assert len(exact_records) == 2
        print("âœ… Exact limit handling: No unnecessary cleanup")

        # Test large input/output data
        large_input = "Large input data " * 100  # ~1700 characters
        large_output = "Large output data " * 100  # ~1800 characters

        await db.save_conversation(
            session_id="large_data_session",
            source="large_tool",
            input_data=large_input,
            output=large_output,
        )

        large_records = await db.get_session_conversations("large_data_session")
        assert len(large_records) == 1
        assert len(large_records[0].input) > 1000
        assert len(large_records[0].output) > 1000
        print("âœ… Large data handling: Correct storage and retrieval")

        print("âœ… All edge cases handled correctly")


if __name__ == "__main__":
    # Run tests directly for development
    async def run_tests():
        test_instance = TestConversationHistoryLifecycle()
        await test_instance.test_save_retrieve_fifo_cleanup_lifecycle()
        await test_instance.test_multiple_sessions_isolation()
        await test_instance.test_time_based_cleanup_integration()
        await test_instance.test_edge_cases_and_error_handling()
        print("\nðŸŽ‰ ALL CONVERSATION HISTORY LIFECYCLE TESTS PASSED!")

    asyncio.run(run_tests())
