"""
Conversation History Service for MCP Judge Tools.

This service handles:
1. Loading historical context for LLM enrichment
2. Saving tool interactions as conversation records
3. Managing session-based conversation history
"""

from mcp_as_a_judge.db import (
    ConversationHistoryDB,
    ConversationRecord,
    create_database_provider,
)
from mcp_as_a_judge.db.db_config import Config
from mcp_as_a_judge.logging_config import get_logger
from mcp_as_a_judge.utils.token_utils import filter_records_by_token_limit

# Set up logger
logger = get_logger(__name__)


class ConversationHistoryService:
    """Service for managing conversation history in judge tools."""

    def __init__(
        self, config: Config, db_provider: ConversationHistoryDB | None = None
    ):
        """
        Initialize the conversation history service.

        Args:
            config: Application configuration
            db_provider: Optional database provider (will create one if not provided)
        """
        self.config = config
        self.db = db_provider or create_database_provider(config)

    async def load_context_for_enrichment(
        self, session_id: str
    ) -> list[ConversationRecord]:
        """
        Load recent conversation records for LLM context enrichment.

        Two-level filtering approach:
        1. Database already enforces storage limits (record count + token limits)
        2. Load-time filtering ensures history + current fits within LLM context limits

        Args:
            session_id: Session identifier

        Returns:
            List of conversation records for LLM context (filtered for LLM limits)
        """
        logger.info(f"üîç Loading conversation history for session: {session_id}")

        # Load all conversations for this session - database already contains
        # records within storage limits, but we may need to filter further for LLM context
        recent_records = await self.db.get_session_conversations(session_id)

        logger.info(f"üìö Retrieved {len(recent_records)} conversation records from DB")

        # Apply LLM context filtering: ensure history + current prompt will fit within token limit
        # This filters the list without modifying the database (only token limit matters for LLM)
        filtered_records = filter_records_by_token_limit(recent_records)

        logger.info(
            f"‚úÖ Returning {len(filtered_records)} conversation records for LLM context"
        )
        return filtered_records

    async def save_tool_interaction(
        self, session_id: str, tool_name: str, tool_input: str, tool_output: str
    ) -> str:
        """
        Save a tool interaction as a conversation record.

        Args:
            session_id: Session identifier from AI agent
            tool_name: Name of the judge tool (e.g., 'judge_coding_plan')
            tool_input: Input that was passed to the tool
            tool_output: Output/result from the tool

        Returns:
            ID of the created conversation record
        """
        logger.info(
            f"üíæ Saving tool interaction to SQLite DB for session: {session_id}, tool: {tool_name}"
        )

        record_id = await self.db.save_conversation(
            session_id=session_id,
            source=tool_name,
            input_data=tool_input,
            output=tool_output,
        )

        logger.info(f"‚úÖ Saved conversation record with ID: {record_id}")
        return record_id

    async def get_conversation_history(
        self, session_id: str
    ) -> list[ConversationRecord]:
        """
        Get conversation history for a session to be injected into user prompts.

        Args:
            session_id: Session identifier

        Returns:
            List of conversation records for the session (most recent first)
        """
        logger.info(f"üîÑ Loading conversation history for session {session_id}")

        context_records = await self.load_context_for_enrichment(session_id)

        logger.info(
            f"üìù Retrieved {len(context_records)} conversation records for session {session_id}"
        )

        return context_records

    def format_conversation_history_as_json_array(
        self, conversation_history: list[ConversationRecord]
    ) -> list[dict]:
        """
        Convert conversation history list to JSON array for prompt injection.

        Args:
            conversation_history: List of conversation records

        Returns:
            List of dictionaries with conversation history data including timestamps
        """
        if not conversation_history:
            return []

        logger.info(
            f"üìù Formatting {len(conversation_history)} conversation records as JSON array"
        )

        json_array = []
        for record in conversation_history:
            json_array.append(
                {
                    "source": record.source,
                    "input": record.input,
                    "output": record.output,
                    "timestamp": record.timestamp.isoformat(),
                }
            )

        logger.info(f"üìù Generated JSON array with {len(json_array)} records")
        return json_array
