"""
Data models and schemas for MCP as a Judge.

This module contains all Pydantic models used for data validation,
serialization, and API contracts.
"""
from datetime import datetime

from pydantic import BaseModel, Field

from mcp_as_a_judge.llm_integration import LLMConfig


class JudgeResponse(BaseModel):
    """Response model for all judge tool evaluations.

    This standardized response format ensures consistent feedback
    across all evaluation tools.
    """

    approved: bool = Field(
        description="Whether the plan/code is approved for implementation"
    )
    required_improvements: list[str] = Field(
        default_factory=list,
        description="Specific improvements needed (empty if approved)",
    )
    feedback: str = Field(
        description="Detailed explanation of the decision and recommendations"
    )


class ObstacleResolutionDecision(BaseModel):
    """Schema for eliciting user decision when agent encounters obstacles.

    Used by the raise_obstacle tool to capture user choices when
    the agent cannot proceed due to blockers or missing information.
    """

    chosen_option: str = Field(
        description="The option the user chooses from the provided list"
    )
    additional_context: str = Field(
        default="",
        description="Any additional context or modifications the user provides",
    )


# Note: RequirementsClarification and ObstacleResolution models have been replaced
# with dynamic model generation in _generate_dynamic_elicitation_model()
# This allows for context-specific elicitation fields generated by LLM


class WorkflowGuidance(BaseModel):
    """Schema for workflow guidance responses.

    Used by the build_workflow tool to provide
    structured guidance on which tools to use next.
    """

    next_tool: str = Field(
        description="The specific MCP tool that should be called next: 'judge_coding_plan', 'judge_code_change', 'raise_obstacle', or 'elicit_missing_requirements'"
    )
    reasoning: str = Field(
        description="Clear explanation of why this tool should be used next"
    )
    preparation_needed: list[str] = Field(
        default_factory=list,
        description="List of things that need to be prepared before calling the recommended tool",
    )
    guidance: str = Field(
        description="Detailed step-by-step guidance for the AI assistant"
    )


class ResearchValidationResponse(BaseModel):
    """Schema for research validation responses.

    Used by the _validate_research_quality function to parse
    LLM responses about research quality and design alignment.
    """

    research_adequate: bool = Field(
        description="Whether the research is comprehensive enough"
    )
    design_based_on_research: bool = Field(
        description="Whether the design is properly based on research"
    )
    issues: list[str] = Field(
        default_factory=list, description="List of specific issues if any"
    )
    feedback: str = Field(
        description="Detailed feedback on research quality and design alignment"
    )


# Database models for conversation history

class ConversationRecord(BaseModel):
    """Model for conversation history records stored in database."""

    id: str = Field(description="Unique identifier for the conversation record")
    session_id: str = Field(description="Session identifier from AI agent")
    source: str = Field(description="Tool name that generated this record")
    input: str = Field(description="Tool input query")
    output: str = Field(description="Tool output string")
    timestamp: datetime = Field(
        default_factory=datetime.utcnow,
        description="When the conversation record was created"
    )


class DatabaseConfig(BaseModel):
    """Configuration for database connection."""

    url: str = Field(
        default="",
        description=(
            "Database connection URL. Examples:\n"
            "- '' or ':memory:' or 'sqlite://:memory:' -> SQLite in-memory\n"
            "- 'sqlite:///path/to/file.db' -> SQLite file\n"
            "- 'postgresql://user:pass@host:port/db' -> PostgreSQL\n"
            "- 'mysql://user:pass@host:port/db' -> MySQL"
        )
    )
    max_context_records: int = Field(
        default=20,
        description="Maximum number of conversation records to keep per session (LRU cleanup)"
    )
    context_enrichment_count: int = Field(
        default=5,
        description="Number of recent conversation records to load for LLM context enrichment"
    )
    record_retention_days: int = Field(
        default=1,
        description="Number of days to keep conversation records before automatic deletion"
    )
    log_truncate_length: int = Field(
        default=100,
        description="Maximum characters to show in logs for input/output (0 = no truncation)"
    )
    cleanup_enabled: bool = Field(
        default=True,
        description="Whether to enable automatic cleanup of old records (runs daily)"
    )


# Type aliases for better code readability
ToolResponse = JudgeResponse
ElicitationResponse = str


# Prompt variable models for type safety and validation


class JudgeCodingPlanSystemVars(BaseModel):
    """Variables for judge_coding_plan system prompt."""

    response_schema: str = Field(
        description="JSON schema for the expected response format"
    )


class JudgeCodingPlanUserVars(BaseModel):
    """Variables for judge_coding_plan user prompt."""

    user_requirements: str = Field(
        description="The user's requirements for the coding task"
    )
    context: str = Field(description="Additional context about the task")
    plan: str = Field(description="The coding plan to be evaluated")
    design: str = Field(description="The design documentation")
    research: str = Field(description="Research findings and analysis")
    research_urls: list[str] = Field(
        default_factory=list,
        description="URLs from MANDATORY online research - minimum 3 URLs required",
    )


class JudgeCodeChangeSystemVars(BaseModel):
    """Variables for judge_code_change system prompt."""

    response_schema: str = Field(
        description="JSON schema for the expected response format"
    )


class JudgeCodeChangeUserVars(BaseModel):
    """Variables for judge_code_change user prompt."""

    user_requirements: str = Field(
        description="The user's requirements for the code change"
    )
    file_path: str = Field(description="Path to the file being changed")
    change_description: str = Field(description="Description of what the change does")
    code_change: str = Field(description="The actual code content being reviewed")


class ResearchValidationSystemVars(BaseModel):
    """Variables for research_validation system prompt."""

    response_schema: str = Field(
        description="JSON schema for the expected response format"
    )


class ResearchValidationUserVars(BaseModel):
    """Variables for research_validation user prompt."""

    user_requirements: str = Field(description="The user's requirements for the task")
    plan: str = Field(description="The proposed plan")
    design: str = Field(description="The design documentation")
    research: str = Field(description="Research findings to be validated")
    research_urls: list[str] = Field(
        default_factory=list,
        description="URLs from MANDATORY online research - minimum 3 URLs required",
    )


class WorkflowGuidanceSystemVars(BaseModel):
    """Variables for build_workflow system prompt."""

    response_schema: str = Field(
        description="JSON schema for the expected response format"
    )


class WorkflowGuidanceUserVars(BaseModel):
    """Variables for build_workflow user prompt."""

    task_description: str = Field(description="Description of the development task")
    context: str = Field(description="Additional context about the task")


class ValidationErrorSystemVars(BaseModel):
    """Variables for validation_error system prompt."""

    # No additional variables needed for system prompt


class ValidationErrorUserVars(BaseModel):
    """Variables for validation_error user prompt."""

    validation_issue: str = Field(
        description="The specific validation issue that occurred"
    )
    context: str = Field(description="Additional context about the validation failure")


class DynamicSchemaSystemVars(BaseModel):
    """Variables for dynamic_schema system prompt."""

    # No additional variables needed for system prompt


class DynamicSchemaUserVars(BaseModel):
    """Variables for dynamic_schema user prompt."""

    context: str = Field(
        description="Context about what information needs to be gathered"
    )
    information_needed: str = Field(
        description="Specific description of what information is needed from the user"
    )
    current_understanding: str = Field(
        description="What we currently understand about the situation"
    )


class ServerConfig(BaseModel):
    """Server configuration including LLM fallback settings."""

    llm_config: LLMConfig | None = Field(
        default=None,
        description="LLM configuration for fallback when MCP sampling is not available",
    )
    enable_llm_fallback: bool = Field(
        default=True,
        description="Whether to enable LLM fallback when MCP sampling is not available",
    )


class ElicitationFallbackUserVars(BaseModel):
    """Variables for elicitation fallback user prompt template."""

    original_message: str = Field(
        description="The original elicitation message that was intended for the user"
    )
    required_fields: list[str] = Field(
        description="List of required field descriptions for the user to provide"
    )
    optional_fields: list[str] = Field(
        description="List of optional field descriptions for the user to provide"
    )
