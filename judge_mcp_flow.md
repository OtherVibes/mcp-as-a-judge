# ğŸ¤– AI Agent with MCP as a Judge - Complete Workflow Diagram

## ğŸ“‹ **System Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ¤– AI Coding Assistant                                â”‚
â”‚                        (Cursor / Claude / VS Code)                             â”‚
â”‚                    â”Œâ”€â”€â”€ Orchestrates all MCP servers â”€â”€â”€â”                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                                     â”‚
                     â–¼                                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    âš–ï¸ MCP as a Judge     â”‚                     â”‚    ğŸ› ï¸ Other MCP Servers â”‚
    â”‚  (Quality Validator +   â”‚                     â”‚                         â”‚
    â”‚   Context Memory)       â”‚                     â”‚  ğŸ“ File System MCP     â”‚
    â”‚                         â”‚                     â”‚  ğŸŒ Web Search MCP      â”‚
    â”‚ â€¢ build_workflow        â”‚                     â”‚  ğŸ”„ Git MCP             â”‚
    â”‚ â€¢ judge_coding_plan     â”‚                     â”‚  ğŸ—„ï¸ Database MCP        â”‚
    â”‚ â€¢ judge_code_change     â”‚                     â”‚  ğŸ”Œ API MCP             â”‚
    â”‚ â€¢ raise_obstacle        â”‚                     â”‚  ğŸ§ª Testing MCP         â”‚
    â”‚ â€¢ raise_missing_req     â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                         â”‚
    â”‚ ğŸ§  Built-in Memory:     â”‚
    â”‚ ğŸ“Š SQLite In-Memory DB  â”‚
    â”‚ â€¢ Conversation history  â”‚
    â”‚ â€¢ Context enrichment    â”‚
    â”‚ â€¢ LRU cleanup          â”‚
    â”‚ â€¢ Session management   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     ğŸ‘¤ Developer        â”‚
    â”‚   (User Involvement)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ **Why MCP As A Judge?**

**AI agent feedback loop can be implemented in 2 main approaches:**

***AI agent (reviewer) which validate the response that was created by another AI agent**

***MCP server (this project) which does not change AI workflow, instead it's added as a seamless plugin (tool) in the existing AI workflow**

## MCP Judge server use MCP concepts:

## ğŸ§  **MCP Sampling**

**MCP Sampling** = MCP server ask (using prompt) an AI assistant's LLM or any other another LLM which of the Judge mcp tool needs to be invoke next (brain remain LLM)

## ğŸ¤ **MCP Elicitation**

**MCP Elicitation** = LLM ask Judge MCP server to asks the **human user** interactive questions and waits for their response

```
âš–ï¸ LLM I need more info --> Judge MCP Server: "I need the user to make a decision"
        â”‚
        â”œâ”€â”€â”€ Creates interactive form/dialog with options
        â”œâ”€â”€â”€ Sends to user via ctx.elicit(message="Choose option A, B, or C", schema=...)
        â”œâ”€â”€â”€ ğŸ‘¤ User sees dialog in their AI assistant interface
        â”œâ”€â”€â”€ ğŸ‘¤ User selects option and provides input
        â””â”€â”€â”€ Judge gets user's decision and continues workflow
```

**Key Point**: Judge MCP pauses the workflow and waits for human input when decisions are needed!

## âš–ï¸ **MCP Sampling vs MCP Elicitation - Key Differences**

| Feature              | ğŸ§  MCP Sampling | ğŸ¤ MCP Elicitation |
|----------------------|----------------|-------------------|
| **Who responds?**    | ğŸ¤– AI Model | ğŸ‘¤ Human User |
| **Purpose**          | Get AI analysis/evaluation | Get user decisions/clarifications |
| **When used?**       | Quality validation, technical analysis | Obstacle resolution, missing requirements |
| **Response time**    | Instant (milliseconds) | Waits for user (minutes/hours) |
| **Example question** | "Is this code secure?" | "Which approach do you prefer?" |
| **Code call**        | `ctx.session.create_message()` | `ctx.elicit()` |
| **Response format**  | Text/JSON analysis | Structured form data |
| **Workflow impact**  | Continues immediately | Pauses until user responds |


**Example Workflow:**
```
1. ğŸ§  Judge MCP uses MCP Sampling: "Is this code secure?" â†’ AI: "Has SQL injection vulnerability" --> AI calls judge MCP raise_obstacle()
2. ğŸ¤ MCP Elicitation: "How should we fix it?" â†’ User: "Use parameterized queries"
3. ğŸ§  MCP Sampling: "Is the fix correct?" â†’ AI: "Yes, vulnerability resolved"
```

## ğŸ§  **Judge MCP Built-in Memory - Context & Learning**

### **Why Memory is Essential for Judge MCP**

The Judge MCP has **built-in conversation history** to make **better, context-aware decisions**:

- **ğŸ” Context Continuity**: Remember previous tool interactions and decisions
- **ğŸ“ˆ Session Learning**: Build context from conversation history within session
- **ğŸš« Avoid Repetition**: Reference previous decisions and feedback
- **ğŸ¯ Informed Decisions**: Each tool call enriched with historical context

### **SQLite In-Memory Database with Conversation History**

#### **ğŸ“Š SQLite In-Memory Conversation History**
```
Purpose: Store conversation history and provide context enrichment for LLM sampling
Features: LRU cleanup, session isolation, context loading for tool enrichment

CONVERSATION HISTORY WORKFLOW:
âœ… Before each tool: Load last X conversation records for context enrichment
âœ… After each tool: Save tool interaction (input, output, context IDs)
âœ… LRU cleanup: Automatically remove oldest records when max limit exceeded
âœ… Session isolation: Each session maintains separate conversation history

Storage Schema (SQLite In-Memory):
CREATE TABLE conversation_history (
    id TEXT PRIMARY KEY,                    -- UUID for each conversation
    session_id TEXT NOT NULL,               -- Session identifier from AI agent
    source TEXT NOT NULL,                   -- Tool name (e.g., "judge_coding_plan")
    input TEXT NOT NULL,                    -- Tool input as JSON string
    context TEXT NOT NULL,                  -- JSON array of conversation IDs used for enrichment
    output TEXT NOT NULL,                   -- Tool output as JSON string
    timestamp TEXT NOT NULL                 -- ISO format datetime
);

Configuration:
{
  "database": {
    "provider": "in_memory",
    "max_context_records": 20,              -- Total records to keep per session (LRU)
    "context_enrichment_count": 5           -- Records to load for LLM context
  }
}

Example Record:
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "session_id": "session-abc",
  "source": "judge_coding_plan",
  "input": "{\"plan\": \"REST API\", \"user_requirements\": \"...\"}",
  "context": "[\"uuid-123\", \"uuid-789\"]",
  "output": "{\"approved\": true, \"feedback\": \"Good plan\"}",
  "timestamp": "2024-01-15T10:30:00.000Z"
}

API Operations:
â€¢ save_conversation(session_id, source, input_data, context, output) â†’ Save tool interaction
â€¢ get_session_conversations(session_id, limit) â†’ Get recent conversations for session
â€¢ get_recent_conversations(session_id, count) â†’ Get conversation IDs for context
â€¢ clear_session(session_id) â†’ Remove all conversations for session
```

### **ğŸ—ï¸ Judge MCP Conversation History Architecture**

```
User Input: "Build REST API with S3 file storage"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ¤– AI Agent Orchestrator                          â”‚
â”‚ 1. Receives user input                                                      â”‚
â”‚ 2. Calls Judge MCP build_workflow() with session_id                         â”‚
â”‚ 3. Orchestrates other MCP servers based on Judge guidance                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        âš–ï¸ Judge MCP Server                                  â”‚
â”‚                                                                             â”‚
â”‚  ğŸ“Š SQLite In-Memory Database (conversation_history table)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ BEFORE Tool Execution: Context Enrichment                          â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚ â”‚ 1. Load last 5 conversation records for session            â”‚     â”‚   â”‚
â”‚  â”‚ â”‚ 2. Format as context for LLM enrichment                    â”‚     â”‚   â”‚
â”‚  â”‚ â”‚ 3. Append to original tool prompt                          â”‚     â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚ DURING Tool Execution: LLM Sampling                                â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚ â”‚ â€¢ Original prompt + conversation history context            â”‚     â”‚   â”‚
â”‚  â”‚ â”‚ â€¢ LLM makes informed decision based on past interactions   â”‚     â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚ AFTER Tool Execution: Save Conversation Record                     â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚ â”‚ ConversationRecord {                                        â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   id: "uuid-123",                                           â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   session_id: "session-abc",                                â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   source: "judge_coding_plan",                              â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   input: "{\"plan\": \"...\", \"requirements\": \"...\"}",  â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   context: ["uuid-456", "uuid-789"],  // Previous conv IDs â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   output: "{\"approved\": true, \"feedback\": \"...\"}",    â”‚     â”‚   â”‚
â”‚  â”‚ â”‚   timestamp: "2024-01-15T10:30:00Z"                        â”‚     â”‚   â”‚
â”‚  â”‚ â”‚ }                                                           â”‚     â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚ LRU Cleanup: If session > max_context_records (20)                 â”‚   â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚
â”‚  â”‚ â”‚ â€¢ Automatically remove oldest conversation records          â”‚     â”‚   â”‚
â”‚  â”‚ â”‚ â€¢ Keep only most recent 20 records per session             â”‚     â”‚   â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **âš™ï¸ Conversation History Configuration**

#### **ğŸ—„ï¸ LRU Cleanup & Session Management**

**Problem:** Without limits, conversation history can grow indefinitely causing:
- ğŸ’¾ Memory bloat (SQLite in-memory database consuming all RAM)
- ğŸŒ Performance degradation (Context loading getting slower)
- ğŸ§  Context overload (Too much history confusing LLM decisions)

**Solution:** Automatic LRU cleanup per session:

```json
{
  "database": {
    "provider": "in_memory",
    "max_context_records": 20,        // Total records to keep per session
    "context_enrichment_count": 5     // Records to load for LLM context
  }
}
```

#### **ğŸ¯ Recommended Configuration Settings**

| Environment | max_context_records | context_enrichment_count | Use Case |
|-------------|-------------------|-------------------------|----------|
| **Development** | 10 | 3 | Fast testing, minimal memory |
| **Production** | 20 | 5 | Balanced performance/memory |
| **High-Volume** | 50 | 10 | Power users, more context |
| **Constrained** | 5 | 2 | Limited resources |

## ğŸ”„ **Complete Development Workflow with Memory**

### **Phase 1: Initial Request & Workflow Guidance**

```
ğŸ‘¤ Developer: "Build a REST API for user management"
        â”‚
        â–¼
ğŸ¤– AI Assistant: Receives request â†’ Its coding task so AI assistant call Judge MCP build_workflow()
        â”‚
        â–¼
âš–ï¸ Judge MCP: build_workflow(task_description)
        â”‚
        â”œâ”€â”€â”€ ğŸ“š Load Conversation History Context
        â”‚    â”œâ”€â”€â”€ ğŸ“Š SQLite: get_recent_conversations(session_id, count=5) â†’ return last 5 conversation IDs
        â”‚    â””â”€â”€â”€ ğŸ“ Format: Load full conversation records and format for LLM context enrichment
        â”‚
        â”œâ”€â”€â”€ ğŸ§  MCP Sampling (Ask AI for workflow guidance - which of Judge MCP tools to call next)
        â”‚    â”œâ”€â”€â”€ AI Prompt: "What workflow steps needed for REST API task?"
        â”‚    â”œâ”€â”€â”€ Context: "## Previous Conversation History\n### 1. judge_coding_plan...\n### 2. judge_code_change..."
        â”‚    â””â”€â”€â”€ AI Response: "This needs planning phase - recommend judge_coding_plan"
        â”‚
        â””â”€â”€â”€ ğŸ’¾ Save Tool Interaction & Return Guidance
             â”œâ”€â”€â”€ Save: ConversationRecord(source="build_workflow", input="{...}", output="{...}", context=[...])
             â””â”€â”€â”€ Response: next_tool="judge_coding_plan", guidance="Start planning..."

ğŸ¯ KEY POINT: LLM used in this flow to answer which mcp judge tool to call next according to the context:

   Task: "Build new REST API" 
   â†’ AI Analysis: "This needs planning first"
   â†’ Result: next_tool = "judge_coding_plan"
   
   Task: "Fix this bug in existing code"
   â†’ AI Analysis: "This is code modification, review the change"  
   â†’ Result: next_tool = "judge_code_change"
   
   Task: "I want to add authentication but not sure which type"
   â†’ AI Analysis: "Requirements are unclear"
   â†’ Result: next_tool = "raise_missing_requirements"
   
   Task: "Database is down, can't continue development"
   â†’ AI Analysis: "This is a blocker/obstacle"
   â†’ Result: next_tool = "raise_obstacle"
```

### **Phase 2: AI Agent Orchestrates Research (Judge MCP Not Involved)**

```
ğŸ¤– AI Assistant: Receives Judge guidance like need to create planâ†’ AI CHOOSES which MCP servers to use for research task
        â”‚
        â”œâ”€â”€â”€ ğŸŒ Web Search MCP: "REST API best practices"
        â”‚    â””â”€â”€â”€ Returns: Documentation, tutorials, security guides
        â”‚
        â”œâ”€â”€â”€ ğŸ“ File System MCP: "existing_patterns.py"
        â”‚    â””â”€â”€â”€ Returns: Current codebase patterns
        â”‚
        â””â”€â”€â”€ ğŸ—„ï¸ Database MCP: get_schema_info()
             â””â”€â”€â”€ Returns: Current database structure

ğŸ¯ IMPORTANT: AI Assistant orchestrates - Judge MCP doesn't choose these servers!
```

### **Phase 3: Planning & Design Validation**

```
ğŸ¤– AI Assistant: Creates comprehensive plan using research from multiple MCP servers with Judge mcp server
   Phase 2 output is fed into Judge MCP server which will use LLM to evaluate the plan
        â”‚
        â–¼
âš–ï¸ Judge MCP: judge_coding_plan(plan, design, research, user_requirements)
        â”‚
        â”œâ”€â”€â”€ ğŸ“š Load Conversation History Context
        â”‚    â”œâ”€â”€â”€ ğŸ“Š SQLite: get_recent_conversations(session_id, count=5) â†’ return conversation IDs
        â”‚    â””â”€â”€â”€ ğŸ“ Format: "## Previous Conversation History\n### 1. build_workflow: next_tool=judge_coding_plan\n### 2. judge_code_change: rejected - security issues"
        â”‚
        â”œâ”€â”€â”€ ğŸ§  MCP Sampling (Ask AI to evaluate plan quality)
        â”‚    â”œâ”€â”€â”€ AI Prompt: "Evaluate this plan for quality and security"
        â”‚    â”œâ”€â”€â”€ Context: Previous conversation history + current plan details
        â”‚    â””â”€â”€â”€ AI Response: "Plan APPROVED - addresses previous security concerns"
        â”‚
        â””â”€â”€â”€ ğŸ’¾ Save Tool Interaction & Return Result
             â”œâ”€â”€â”€ Save: ConversationRecord(source="judge_coding_plan", input="{plan, design, research...}", output="{approved: true, feedback...}", context=[...])
             â””â”€â”€â”€ Response: approved=true, guidance="Proceed to implementation" OR Reject

ğŸ“‹ **Plan Evaluation Results:**
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… APPROVED                    â”‚  âŒ REJECTED                   â”‚
â”‚  â€¢ Plan meets standards         â”‚  â€¢ Missing security measures   â”‚
â”‚  â€¢ Research is thorough         â”‚  â€¢ Insufficient error handling â”‚
â”‚  â€¢ Architecture is sound        â”‚  â€¢ Needs more research         â”‚
â”‚  â†’ Proceed to implementation    â”‚  â†’ Return to planning phase    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Phase 4: Implementation with Continuous Review**

```
Now plan approved start to implement and once agent finished to code change ??? , judge mcp will review the results by send LLM to vaerify change is accordingn to standards
ğŸ¤– AI Assistant: Begins implementation using File System MCP
        â”‚
        â”œâ”€â”€â”€ ğŸ“ File System MCP: create_file("api/users.py", code_content)
        â”‚
        â–¼
âš–ï¸ Judge MCP: judge_code_change(code, user_requirements, file_path) -- Code review cycles
        â”‚
        â”œâ”€â”€â”€ ğŸ“š Load Memory Context
        â”‚    â”œâ”€â”€â”€ ğŸ” Vector: "SQL injection security" â†’ User had issues before
        â”‚    â””â”€â”€â”€ ğŸ“Š Rational: "Approved bcrypt, rejected raw SQL concatenation"
        â”‚
        â”œâ”€â”€â”€ ğŸ§  MCP Sampling (Ask AI to review code quality of new file users.py)
        â”‚    â”œâ”€â”€â”€ AI Prompt: "Review this code for security vulnerabilities"
        â”‚    â”œâ”€â”€â”€ Context: "User concerned about SQL injection, prefers parameterized queries"
        â”‚    â””â”€â”€â”€ AI Response: "Code APPROVED - proper parameterized queries used"
        â”‚
        â””â”€â”€â”€ ğŸ’¾ Save Review & Return Result
             â””â”€â”€â”€ Response: approved=true, guidance="Continue workflow"
             â””â”€â”€â”€ On next change ??? there will be another judge validation cycle 

ğŸ” **Code Review Results:**
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ… APPROVED                    â”‚  âŒ NEEDS IMPROVEMENT          â”‚
â”‚  â€¢ Code follows best practices  â”‚  â€¢ Security vulnerabilities    â”‚
â”‚  â€¢ Proper error handling        â”‚  â€¢ Performance issues          â”‚
â”‚  â€¢ Good documentation           â”‚  â€¢ Missing validations         â”‚
â”‚  â†’ Continue workflow            â”‚  â†’ Fix issues & re-review      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```



## ğŸ¤ **User Involvement Scenarios**

### **Scenario A: Obstacle Encountered**

**LLM Detects conflicting requirements and suggest to invoke judge mcp raise_obstacle() with some options**

1. **âš–ï¸ Judge:** raise_obstacle()
   - **Obstacle:** "Database schema conflicts with API design"
   - **Options:** ["Modify schema", "Adjust API", "Create migration"]

2. **ğŸ¤ MCP Elicitation:** Present options to user

3. **ğŸ‘¤ Developer:** Makes decision â†’ "Create migration"

4. **ğŸ¤– AI Assistant:** Continues with user's choice

### **Scenario B: Requirements Unclear**

**LLM Detects missing informatio and suggest to invoke judge mcp raise_missing_requirements() with some options**

1. **âš–ï¸ Judge:** raise_missing_requirements()
   - **Gaps:** ["Authentication method", "Rate limiting", "Data validation rules"]
   - **Questions:** ["Should we use JWT?", "What's the rate limit?", "Required fields?"]

2. **ğŸ¤ MCP Elicitation:** Ask user for clarifications

3. **ğŸ‘¤ Developer:** Provides missing requirements

4. **ğŸ¤– AI Assistant:** Continues with clarified requirements

## ğŸ§  **Judge MCP Features**

**ğŸ“‹ judge_coding_plan():**
- Creates evaluation prompt from Jinja2 template
- ctx.session.create_message(messages=prompts, max_tokens=1000)
- AI model analyzes: plan quality, security, best practices
- Returns structured JudgeResponse

**ğŸ” judge_code_change():**
- Creates code review prompt from Jinja2 template
- ctx.session.create_message(messages=prompts, max_tokens=1000)
- AI model analyzes: code quality, vulnerabilities, maintainability
- Returns structured JudgeResponse

**ğŸš¨ raise_obstacle():**
- Creates interactive dialog with options
- ctx.elicit(message="ğŸš¨ OBSTACLE: Choose approach...", schema=dynamic_form)
- ğŸ‘¤ User sees form in AI assistant interface
- ğŸ‘¤ User selects option and provides context
- Returns user's decision to continue workflow

**ğŸ” raise_missing_requirements():**
- Creates clarification form with questions
- ctx.elicit(message="ğŸ” CLARIFICATION NEEDED...", schema=requirements_form)
- ğŸ‘¤ User fills out missing requirements and priorities
- ğŸ‘¤ User submits completed form
- Returns clarified requirements to continue workflow

## ğŸ—„ï¸ **Conversation History Patterns & Usage Guide**

### **ğŸ“Š SQLite Conversation History Operations**

#### **Pattern 1: Recent Entries (Any Source)**
```python
# Use Case: Get overall recent activity
recent_entries = memory.get_last_n_entries(session_id="user_123", n=5)

# Returns (most recent first):
[
  {"content": "build_workflow result: next_tool=judge_coding_plan", "source": "judge_mcp"},
  {"content": "User chose JWT over sessions", "source": "judge_mcp"},
  {"content": "Applied context: User's JWT preference", "source": "judge_mcp"},
  {"content": "AI evaluation: Recommend planning workflow", "source": "judge_mcp"},
  {"content": "judge_coding_plan called with plan='...'", "source": "judge_mcp"}
]
```

#### **Pattern 2: Recent Judge Decisions Only** // can be any source (mcp tool)
```python
# Use Case: Get recent judge-specific decisions
judge_decisions = memory.get_last_n_entries(session_id="user_123", n=3, source="judge_mcp")

# Returns (most recent first):
[
  {"content": "judge_coding_plan result: APPROVED", "source": "judge_mcp"},
  {"content": "judge_code_change result: REJECTED - SQL injection", "source": "judge_mcp"},
  {"content": "build_workflow result: next_tool=judge_coding_plan", "source": "judge_mcp"}
]
```

### **ğŸ” Vector Memory Query Patterns (Complex Semantic)**

```python
# Use Case: Find user's security-related patterns
security_patterns = memory.query_vector(
    query="security vulnerability SQL injection validation sanitization",
    top_k=3,
    session_id="user_123"
)

# Returns:
[
  {"content": "User concerned about SQL injection vulnerabilities", "score": 0.91},
  {"content": "User implements input validation and sanitization", "score": 0.87},
  {"content": "User adds rate limiting for API security", "score": 0.83}
]
```

### **ğŸ¯ Memory Usage Decision Matrix**

| Scenario | Memory Type | Query Pattern | Example |
|----------|-------------|---------------|---------|
| **Recent decisions** | ğŸ“Š Relational | `get_last_n_entries(session_id, n)` | "What did I decide recently?" |
| **Recent judge actions** | ğŸ“Š Relational | `get_last_n_entries(session_id, n, "judge_mcp")` | "Last 3 judge decisions" |
| **Security patterns** | ğŸ” Vector | `query_vector("security vulnerability", top_k)` | "User's security practices" |


#### **Every Judge MCP Tool Saves Complete Execution:**

```python
# COMPLETE TOOL EXECUTION (Input + Output in one atomic operation)
save_entry(
    session_id=session_id,
    source="judge_mcp",
    tool_name="judge_coding_plan",  # build_workflow, judge_code_change, raise_obstacle, raise_missing_requirements
    input={
        "user_requirements": "Build REST API for user management",
        "plan": "1. Create user model with validation...",
        "design": "Architecture: Express.js + PostgreSQL...",
        "research": "Found libraries: bcrypt, joi, express-validator...",
        "research_urls": ["https://...", "https://...", "https://..."]
    },
    output={
        "approved": true,
        "required_improvements": [],
        "feedback": "Plan follows all best practices. Good security considerations..."
    },
    timestamp=1690000000
)
```

## ğŸ“‹ **Real Examples: Sampling vs Elicitation in Action**

### **Example 1: Code Security Review**

```
ğŸ§  MCP Sampling Example:
âš–ï¸ Judge: judge_code_change(code="SELECT * FROM users WHERE id = " + user_id)
        â”‚
        â”œâ”€â”€â”€ Creates prompt: "Analyze this SQL code for security vulnerabilities"
        â”œâ”€â”€â”€ ctx.session.create_message(messages=[security_analysis_prompt])
        â”œâ”€â”€â”€ ğŸ¤– AI Model: "CRITICAL: SQL injection vulnerability detected on line 1..."
        â””â”€â”€â”€ Returns: JudgeResponse(approved=false, required_improvements=["Fix SQL injection"])
```

### **Example 2: User Decision on Fix Approach**

```
ğŸ¤ MCP Elicitation Example:
âš–ï¸ Judge: raise_obstacle(
   problem="SQL injection found",
   options=["Use ORM", "Parameterized queries", "Input validation"]
)
        â”‚
        â”œâ”€â”€â”€ Creates dialog: "ğŸš¨ OBSTACLE: How should we fix the SQL injection?"
        â”œâ”€â”€â”€ ctx.elicit(message="Choose approach:", schema=choice_form)
        â”œâ”€â”€â”€ ğŸ‘¤ User sees options in AI assistant interface
        â”œâ”€â”€â”€ ğŸ‘¤ User selects: "Use parameterized queries + input validation"
        â””â”€â”€â”€ Returns: "Proceed with parameterized queries and input validation approach"
```

### **Example 3: Requirements Clarification**

```
ğŸ¤ MCP Elicitation Example:
âš–ï¸ Judge: raise_missing_requirements(gaps=["Authentication method", "Session duration"])
        â”‚
        â”œâ”€â”€â”€ Creates form: "ğŸ” CLARIFICATION: Please specify authentication details"
        â”œâ”€â”€â”€ ctx.elicit(message="Missing requirements:", schema=requirements_form)
        â”œâ”€â”€â”€ ğŸ‘¤ User fills form:
        â”‚    â€¢ Authentication: "JWT tokens"
        â”‚    â€¢ Session duration: "24 hours"
        â”‚    â€¢ Priority: "High"
        â””â”€â”€â”€ Returns: "Use JWT tokens with 24-hour expiration (High priority)"
```

## âš ï¸ **Error Handling & Fallbacks**

### **When MCP Sampling Fails**

```
âš–ï¸ Judge MCP: Attempts AI evaluation
        â”‚
        â”œâ”€â”€â”€ ğŸ§  MCP Sampling: FAILED
        â”‚
        â–¼
âš–ï¸ Judge: Provides fallback guidance
   â€¢ Default recommendations
   â€¢ Basic validation rules
   â€¢ Conservative approach
```

### **When User is Unavailable**

```
âš–ï¸ Judge MCP: Needs user input
        â”‚
        â”œâ”€â”€â”€ ğŸ¤ MCP Elicitation: User not responding
        â”‚
        â–¼
âš–ï¸ Judge: Queue workflow
   â€¢ Pause implementation
   â€¢ Save current state
   â€¢ Wait for user availability
```

## ğŸ¯ **Key Benefits of This Architecture**

### **1. Structured Workflow Enforcement**
- âœ… Mandatory planning phase
- âœ… Continuous code review
- âœ… Quality gates at each step

### **2. Multi-MCP Coordination**
- âš–ï¸ Judge MCP orchestrates the workflow
- ğŸ› ï¸ Specialized MCPs handle specific tasks
- ğŸ¤– AI Assistant coordinates all interactions

### **3. User-Driven Decision Making**
- ğŸ¤ No hidden AI assumptions
- ğŸ¤ Transparent obstacle resolution
- ğŸ¤ Interactive requirement gathering

### **4. Professional Development Standards**
- ğŸ“‹ Comprehensive planning required
- ğŸ” Thorough research enforced
- ğŸ›¡ï¸ Security and quality validation
- ğŸ“š Best practices compliance

---

**Result**: A professional, structured development workflow where AI assistants follow software engineering best practices, conduct proper research, validate quality at each step, and involve users in critical decisions.
